# ğŸ¤Ÿ ASL Hand Gesture Recognition

License: MIT  
Built with: Python Â· PyTorch Â· OpenCV Â· Tkinter GUI

An end-to-end deep learning project for real-time American Sign Language (ASL) hand gesture recognition. Includes image preprocessing, CNN training, evaluation metrics, and a drag-and-drop GUI for interactive predictions.

---

ğŸ” FEATURES

- ğŸ¯ High Accuracy CNN classifier for 39 ASL gestures (Aâ€“Z, 0â€“10, space, nothing, del)
- ğŸ› ï¸ Image Preprocessing: Background removal, resizing, normalization
- ğŸ“Š Model Training & Evaluation: Accuracy plots, confusion matrix
- ğŸ–¼ï¸ Interactive GUI: Drag & drop single images or entire folders
- ğŸ’¾ Model Persistence: Save and reload trained PyTorch models

---

ğŸ“¦ PROJECT STRUCTURE

â”œâ”€â”€ Model_Make.ipynb           # Notebook for training the CNN model  
â”œâ”€â”€ GUI.ipynb                  # Notebook for launching drag-and-drop GUI  
â”œâ”€â”€ preprocess.py              # Script to clean, resize, and structure dataset  
â”œâ”€â”€ requirements.txt           # List of dependencies  
â”œâ”€â”€ asl_cnn_39class_cpu.pth    # Saved trained model (PyTorch)  
â”œâ”€â”€ Preprocessed_data/         # Folder with preprocessed images per class  
â”œâ”€â”€ test/                      # Folder with one test image per class  
â””â”€â”€ README.md                  # Project documentation  

---

ğŸ§  MODEL OVERVIEW

- Input Shape: 32x32 RGB  
- Architecture: Custom CNN with 3 conv blocks + dropout + batch norm  
- Classes: 39 total  
- Final Test Accuracy: 98.57%

> Model trained on CPU with over 42,000 images across all classes.

---

ğŸ“ DATASET

This project combines multiple datasets:

ASL Alphabet â€“ Hand signs Aâ€“Z  
https://www.kaggle.com/datasets/grassknoted/asl-alphabet

ASL Numbers â€“ Synthetic hand signs 0â€“10  
https://www.kaggle.com/datasets/lexset/synthetic-asl-numbers

---

ğŸ§ª TECH STACK

Model Training: PyTorch, NumPy, OpenCV  
GUI: Tkinter, TkinterDnD2, Pillow  
Data Processing: Pandas, Matplotlib, Seaborn  
Evaluation: Scikit-learn, Confusion Matrix

---

ğŸš€ GETTING STARTED

1ï¸âƒ£ Clone the Repository

git clone https://github.com/your-username/asl-gesture-recognition.git  
cd asl-gesture-recognition

2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

3ï¸âƒ£ Preprocess the Dataset

python preprocess.py

This script:
- Removes background
- Splits train/test
- Generates `test/` folder with sample images

4ï¸âƒ£ Train the CNN

jupyter notebook Model_Make.ipynb  
(Train the model and save it as asl_cnn_39class_cpu.pth)

5ï¸âƒ£ Launch the GUI

jupyter notebook GUI.ipynb  
Then drag and drop:
- A single image to get prediction and confidence
- A folder to get batch predictions

---

ğŸ§¾ REQUIREMENTS

# Core libraries
numpy==1.26.4  
pandas==2.2.2  
opencv-python==4.9.0.80  
matplotlib==3.8.4  
seaborn==0.13.2  
scikit-learn==1.5.0  

# PyTorch (CPU version)
torch==2.3.0  
torchvision==0.18.0  

# GUI and drag-and-drop
tkinterdnd2==0.3.0  
Pillow==10.3.0  

Note: `tkinter` is part of the Python standard library but must be installed separately (e.g., `sudo apt install python3-tk` on Linux).

---

ğŸ“Š RESULTS SNAPSHOT

Final Accuracy: 98.57%  
Epochs Trained: 10  
Total Images: 42,000+ across 39 classes

---

ğŸ–¼ï¸ GUI PREVIEW

(Add a screenshot of your GUI here, if desired)

---

ğŸ“„ LICENSE

MIT License

---

ğŸ™Œ ACKNOWLEDGMENTS

- ASL Alphabet Dataset â€“ Kaggle  
- ASL Numbers Dataset â€“ Kaggle  
- TkinterDnD2 by pmgagne
